üîÑ SIGUIENTES PRIORIDADES:

  Funcionalidades a agregar / reparar / revisar:
    . Testing/Revisi√≥n
      - (1h) [Revisar] eliminado de b√∫squedas desde interfaz. No quedan guardadas actualmente.
      - (30') [Testear] Las propiedades que encuentran (por ahora solo guarda coincidentes. Deber√≠a guardar las no coincidentes con 'coincide' valor False)
      - (20') [Testear] Guardar caracter√≠sticas en la tabla de propiedades.
      - (45') [Actualizar] Tests para arquitectura modular del scraper
      - (30') [Verificar] Funcionamiento correcto de fallbacks HTTP cuando Redis no disponible
    . (tiempos muertos) Actualizar documentaciones:
    . Agregar
      - (2,5h) Cron jobs para automatizaci√≥n 
      - Que la IA genere sin√≥nimos para la palabra clave
      - Sin subt√≠tulos (nuevas o encontradas anteriormente) en resultados encontrados cuando se busca y guarda por primera vez. (30 mins)
      - Bot√≥n de reiniciar b√∫squeda en b√∫squedas guardadas (2 hs)
      - (1,5h) Expansi√≥n a nuevas plataformas usando arquitectura modular
      - (1h) Sistema de notificaciones push para b√∫squedas automatizadas
      - (45') Mejoras en sistema de cookies y gesti√≥n de sesiones

    . Otras acciones:
    - Optimizar Consultas: A√±adir √≠ndices y select_related (2 hs)
    - Dashboard de m√©tricas y estad√≠sticas (3 hs)
    - (2h) Implementar rate limiting y respeto a robots.txt m√°s robusto
    - (1,5h) Sistema de health checks para monitoreo en producci√≥n
    . Opcionales
    - Documentar integraci√≥n con Google Sheets (en README) y ejemplo de importaci√≥n
    - Ajustar retenci√≥n de snapshots seg√∫n pol√≠tica (keep=N) si se desea hist√≥rico
    - (3h) API REST p√∫blica para integraci√≥n con terceros
    - (2h) Plugin/extensi√≥n de navegador para b√∫squeda r√°pida


üîÆ VISI√ìN FUTURA (2025-2026):

  üåü CARACTER√çSTICAS AVANZADAS:
    - An√°lisis predictivo de precios usando ML/IA (basado en datos propios agregados)
    - Sistema de alertas inteligentes para nuevas publicaciones que coincidan con criterios
    - Estad√≠sticas de mercado agregadas (sin mostrar contenido espec√≠fico de plataformas)
    - Integraci√≥n con APIs p√∫blicas de valuaci√≥n inmobiliaria
    - Sistema de recomendaciones basado en b√∫squedas y preferencias del usuario

  ü§ñ AUTOMATIZACI√ìN INTELIGENTE:
    - Monitoreo continuo de cambios de precios
    - Detecci√≥n autom√°tica de nuevas funcionalidades en sitios
    - Auto-actualizaci√≥n de selectores mediante IA
    - Generaci√≥n autom√°tica de reportes de mercado
    - Sistema de ML para optimizar estrategias de scraping

  üîó INTEGRACIONES ESTRAT√âGICAS:
    - WhatsApp/Telegram bots para notificaciones
    - Integraci√≥n con CRMs inmobiliarios
    - API para desarrolladores de terceros
    - Plugin para navegadores populares
    - Webhook system para actualizaciones en tiempo real

  üì± EXPERIENCIA DE USUARIO:
    - PWA (Progressive Web App) para uso m√≥vil
    - Dashboard personalizable con widgets
    - Sistema de favoritos y listas de seguimiento
    - Buscador inteligente con filtros avanzados
    - Mapas interactivos que deriven a propiedades originales

  üåç EXPANSI√ìN Y ESCALABILIDAD:
    - Soporte multi-pa√≠s (Argentina, Brasil, Chile)
    - Arquitectura multi-tenant para diferentes usuarios
    - Sistema de caching distribuido
    - Load balancing autom√°tico
    - Microservicios para componentes cr√≠ticos

  üõ°Ô∏è COMPLIANCE Y SOSTENIBILIDAD:
    - Cumplimiento GDPR/LGPD para expansi√≥n internacional
    - Sistema de auditor√≠a completo para trazabilidad
    - M√©tricas de impacto ambiental del scraping
    - Pol√≠ticas de fair use y rate limiting inteligente
    - Certificaciones de seguridad y privacy

üéØ HITOS T√âCNICOS CLAVE:
  Q4 2025: Sistema de ML para an√°lisis predictivo
  Q1 2026: PWA y expansi√≥n m√≥vil completa
  Q2 2026: Multi-pa√≠s (Argentina como piloto)
  Q3 2026: API p√∫blica v1.0 y ecosystem de terceros
  Q4 2026: Arquitectura distribuida y microservicios

üí° INNOVACIONES PROPUESTAS (RESPETANDO DERECHOS DE AUTOR):
  - NLP avanzado para mejorar b√∫squedas y filtros
  - Sistema de matching inteligente entre criterios y propiedades
  - Algoritmos de relevancia para ordenar resultados
  - Interfaz de b√∫squeda por voz y lenguaje natural
  - Sistema de notificaciones personalizadas para nuevas publicaciones Crear tests para nuevas funcionalidades (17 tests pasando)
  ‚úÖ COMPLETADO - Documentaci√≥n: Actualizar documentaci√≥n t√©cnica (DOCUMENTACION_TECNICA.md)
  ‚úÖ COMPLETADO - Probar Funcionalidad WebSocket: Redis/Channels funcionando correctamente
  ‚úÖ COMPLETADO - Exportaci√≥n CSV + Auditor√≠a: Endpoints /csv/export/all/, /csv/table/<tabla>/ y /csv/audit/latest/, manifiesto _manifest.json/CSV y poda de snapshots
  ‚úÖ Migrar a PostgreSQL: Para entorno de producci√≥n
  ‚úÖ COMPLETADO - MIGRACI√ìN A BASE DE DATOS RELACIONAL:
    ‚úÖ 8 modelos Django implementados
    ‚úÖ Sistema de sin√≥nimos funcional
    ‚úÖ Compatibilidad con WebSocket/consumers.py
    ‚úÖ Admin panel configurado
    ‚úÖ 17 tests unitarios pasando
    ‚úÖ Redis/Channels Layer funcionando
    ‚úÖ Migraciones aplicadas
    ‚úÖ Datos de ejemplo cargados
    ‚úÖ Performance optimizada (<1 segundo consultas)
  ‚úÖ Se arregl√≥ un bug del frontend que imped√≠a mostrar la lista de publicaciones al finalizar una b√∫squeda (variable JS fuera de scope).
  ‚úÖ Se agreg√≥ b√∫squeda de InfoCasas

  ‚úÖ ARREGLADO - Guardado de publicaciones mejorado con:
    ‚úÖ L√≥gica de keywords m√°s flexible (70% coincidencia)
    ‚úÖ Stemming b√°sico para espa√±ol
    ‚úÖ Mejor manejo de errores
    ‚úÖ Logs m√°s detallados para debug
  ‚úÖ Que la lista de los resultados se guarden en las b√∫squedas guardadas
  ‚úÖ COMPLETADO - Migraci√≥n de scraper monol√≠tico a arquitectura modular:
    ‚úÖ Paquete core/scraper/ implementado con API p√∫blica
    ‚úÖ Separaci√≥n de responsabilidades en m√≥dulos especializados
    ‚úÖ Sistema de progreso y debugging mejorado
    ‚úÖ Soporte dual: Selenium + requests/BS4
    ‚úÖ Integraci√≥n con ScrapingBee opcional
  ‚úÖ COMPLETADO - Sistema de guardado unificado:
    ‚úÖ Diferenciaci√≥n entre b√∫squedas temporales y guardadas
    ‚úÖ Gestor de b√∫squedas (core/search_manager.py)
    ‚úÖ Historial completo mantenido en BD
  ‚úÖ COMPLETADO - Integraci√≥n IA Gemini:
    ‚úÖ An√°lisis autom√°tico de texto libre
    ‚úÖ Inferencia de filtros y keywords
    ‚úÖ Fusi√≥n inteligente con filtros manuales

üöÄ CONSIDERACIONES PARA PRODUCCI√ìN:

  üîß Infraestructura:
    - Redis/Upstash configurado para WebSockets en producci√≥n
    - PostgreSQL como base de datos principal (ver README_POSTGRESQL.md)
    - Configuraci√≥n de variables de entorno para APIs externas (Gemini, ScrapingBee)
    - Sistema de logs estructurado y monitoreo
    - Docker compose para desarrollo y testing local

  üõ°Ô∏è Seguridad y Compliance:
    - Cookies mias: Solucionar de otra forma (¬øcapaz utilizando concurrencia y proxy se soluciona?)
    - Implementar rotaci√≥n de user agents y proxies
    - Validaci√≥n robusta de URLs y filtrado de paths prohibidos (/jms/, /adn/api)
    - Respeto estricto a robots.txt por plataforma
    - Rate limiting configurable por sitio

  üìä Escalabilidad y Performance:
    - Arquitectura modular del scraper permite expansi√≥n horizontal
    - Sistema de cacheado inteligente para URLs y resultados
    - Bulk operations optimizadas para inserci√≥n masiva
    - √çndices de BD optimizados (ya implementados en Meta)
    - Monitoreo de performance con m√©tricas en tiempo real

  üîÑ Mantenimiento y Evoluci√≥n:
    - Selectores CSS/XPath versionados por plataforma
    - Sistema de fallbacks autom√°ticos (Selenium ‚Üî requests/BS4)
    - Tests automatizados para detectar cambios en sitios objetivo
    - Versionado de APIs internas del scraper
    - Health checks autom√°ticos para cada componente

üéâ ESTADO ACTUAL ACTUALIZADO (Sep 2025):
  üì¶ ARQUITECTURA: Sistema modular con core/scraper/ completamente refactorizado
  üß† IA INTEGRADA: Gemini para an√°lisis de texto libre y inferencia de filtros
  üîç MULTI-PLATAFORMA: MercadoLibre e InfoCasas funcionando
  üíæ BASE DE DATOS: Migraci√≥n completa a modelos Django relacionales
  üåê TIEMPO REAL: WebSockets con Redis/fallback HTTP funcional
  üì§ EXPORTACI√ìN: CSV con auditor√≠a y manifiestos automatizados
  ÔøΩ GESTI√ìN: Sistema de b√∫squedas guardadas vs temporales
  üéØ TESTING: Arquitectura robusta con tests automatizados
  ‚ö° PERFORMANCE: Optimizada para grandes vol√∫menes de datos
  üìö DOCUMENTACI√ìN: Gu√≠as t√©cnicas actualizadas y completas
